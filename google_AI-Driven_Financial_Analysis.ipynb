{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GenAI-Powered Risk and Financial Analysis of Appleâ€™s Q1 2025 10-Q \n\n## Objective: \n#### To help investors and individuals without a financial background understand risks from SEC filings using GenAI, leveraging Gemini as a foundational model to enhance the analysis and interpretation of complex financial data.\n\n\nKey Highlights:\n1. Extracts financial tables using Google GenAI prompts\n2. Separates and chunks narrative text for sentiment & risk analysis\n3. Embeds chunked text for search and classification using Google GenAI Embeddings\n4. Generates structured output using agents, and a final PDF report\n5. **Utilizes Gemini as a foundational model to enhance and update the capabilities of the system**\n\nGen AI Capabilities Demonstrated:\n1. Structured output/JSON mode/controlled generation\n2. Few-shot prompting\n3. Document understanding\n4. Image understanding\n5. Function Calling\n6. Agents\n7. Long context window\n8. Grounding\n9. Embeddings\n10. Retrieval augmented generation (RAG)\n11. Vector search/vector store/vector database\n\n","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n!pip install -Uq \"google-genai==1.7.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:28.188057Z","iopub.execute_input":"2025-04-21T06:31:28.188572Z","iopub.status.idle":"2025-04-21T06:31:35.195190Z","shell.execute_reply.started":"2025-04-21T06:31:28.188528Z","shell.execute_reply":"2025-04-21T06:31:35.193236Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"!pip install pdfplumber\n!pip install google-cloud-discoveryengine\n!pip install PyMuPDF\n!pip install google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:35.198101Z","iopub.execute_input":"2025-04-21T06:31:35.198575Z","iopub.status.idle":"2025-04-21T06:31:56.586663Z","shell.execute_reply.started":"2025-04-21T06:31:35.198539Z","shell.execute_reply":"2025-04-21T06:31:56.584485Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.6)\nRequirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20250327)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nRequirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.1)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20250327->pdfplumber) (44.0.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\nRequirement already satisfied: google-cloud-discoveryengine in /usr/local/lib/python3.10/dist-packages (0.13.8)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (1.34.1)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (2.27.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (1.25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (3.20.3)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (1.66.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (2.32.3)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (1.68.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (1.48.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-discoveryengine) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-discoveryengine) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-discoveryengine) (4.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-discoveryengine) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-discoveryengine) (2025.1.31)\nRequirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.25.5)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\nRequirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.155.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.0a2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.29.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown, display\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:56.589418Z","iopub.execute_input":"2025-04-21T06:31:56.589907Z","iopub.status.idle":"2025-04-21T06:31:56.598566Z","shell.execute_reply.started":"2025-04-21T06:31:56.589835Z","shell.execute_reply":"2025-04-21T06:31:56.597163Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"Setup local variables ","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:56.601137Z","iopub.execute_input":"2025-04-21T06:31:56.601640Z","iopub.status.idle":"2025-04-21T06:31:56.936843Z","shell.execute_reply.started":"2025-04-21T06:31:56.601587Z","shell.execute_reply":"2025-04-21T06:31:56.935034Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## File Processing: Parsing, Chunking, Embedding, Vectors Storage and Similarity Search\n\nLoad the SEC report 2025-10-q\n[**[source link]**](https://www.sec.gov/edgar/browse/?CIK=320193&owner=exclude)","metadata":{}},{"cell_type":"code","source":"!wget -nv -O 10Q_Q1_2025_as_filed.pdf https://storage.googleapis.com/cloud-raw-data/pdf/10Q_Q1_2025_as_filed.pdf\n\ndocument_file = client.files.upload(file='10Q_Q1_2025_as_filed.pdf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:56.939031Z","iopub.execute_input":"2025-04-21T06:31:56.939623Z","iopub.status.idle":"2025-04-21T06:31:58.879048Z","shell.execute_reply.started":"2025-04-21T06:31:56.939571Z","shell.execute_reply":"2025-04-21T06:31:58.877405Z"}},"outputs":[{"name":"stdout","text":"2025-04-21 06:31:57 URL:https://storage.googleapis.com/cloud-raw-data/pdf/10Q_Q1_2025_as_filed.pdf [424623/424623] -> \"10Q_Q1_2025_as_filed.pdf\" [1]\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import pdfplumber\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport textwrap\nimport json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Extract text (no tables), use pdfplumber to open the PDF and read each page\ndef raw_text_extraction(pdf_path):\n    text_output = ''\n    with pdfplumber.open(pdf_path) as pdf:\n        for page in pdf.pages:\n            text = page.extract_text()\n            if text:\n                text_output += text + '\\n'\n    return text_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.880990Z","iopub.execute_input":"2025-04-21T06:31:58.881419Z","iopub.status.idle":"2025-04-21T06:31:58.889073Z","shell.execute_reply.started":"2025-04-21T06:31:58.881382Z","shell.execute_reply":"2025-04-21T06:31:58.887173Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"#Split text into chunks (approx. max_tokens tokens)\ndef split_into_chunks(text, max_tokens=300):\n    approx_chunk_len = max_tokens * 4  # 1 token ~ 4 characters (roughly)\n    paragraphs = text.split('\\n\\n')  # basic paragraph split\n    chunks = []\n\n    current_chunk = ''\n    for para in paragraphs:\n        if len(current_chunk) + len(para) < approx_chunk_len:\n            current_chunk += para.strip() + ' '\n        else:\n            chunks.append(current_chunk.strip())\n            current_chunk = para.strip() + ' '\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.890725Z","iopub.execute_input":"2025-04-21T06:31:58.891433Z","iopub.status.idle":"2025-04-21T06:31:58.899110Z","shell.execute_reply.started":"2025-04-21T06:31:58.891375Z","shell.execute_reply":"2025-04-21T06:31:58.897612Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Embeddings are generated in the context of \"QUESTION_ANSWERING\"\ndef embed_chunks_with_genai(client, paragraphs):\n    response = client.models.embed_content(\n        model='models/text-embedding-004',\n        contents=paragraphs,\n        config={\"task_type\":\"QUESTION_ANSWERING\",}\n    )\n    return [embedding.values for embedding in response.embeddings]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.906058Z","iopub.execute_input":"2025-04-21T06:31:58.906507Z","iopub.status.idle":"2025-04-21T06:31:58.912693Z","shell.execute_reply.started":"2025-04-21T06:31:58.906473Z","shell.execute_reply":"2025-04-21T06:31:58.911228Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Store chunks+vectors in DataFrame \ndef build_embedding_dataframe(chunks, embeddings):\n    chunk_ids = [f'chunk{i+1}' for i in range(len(chunks))]\n    df = pd.DataFrame({\n        'chunk_id': chunk_ids,\n        'text': chunks,\n        'embedding': embeddings\n    })\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.915131Z","iopub.execute_input":"2025-04-21T06:31:58.915515Z","iopub.status.idle":"2025-04-21T06:31:58.922233Z","shell.execute_reply.started":"2025-04-21T06:31:58.915483Z","shell.execute_reply":"2025-04-21T06:31:58.920554Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"#Similarity Search using cosine\ndef search_similar_chunks(query, df, client, top_n=3):\n\n    query_response = client.models.embed_content(\n        model='models/text-embedding-004',\n        contents=[query],\n        config=types.EmbedContentConfig(\n            task_type=\"QUESTION_ANSWERING\",\n        )\n    )\n    query_vector = query_response.embeddings[0].values\n    embeddings_matrix = np.vstack(df['embedding'].values)\n    \n    similarities = cosine_similarity([query_vector], embeddings_matrix)[0]\n    df['similarity'] = similarities\n    return df.sort_values('similarity', ascending=False).head(top_n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.923474Z","iopub.execute_input":"2025-04-21T06:31:58.923831Z","iopub.status.idle":"2025-04-21T06:31:58.931279Z","shell.execute_reply.started":"2025-04-21T06:31:58.923801Z","shell.execute_reply":"2025-04-21T06:31:58.929506Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"Utilizing the similarity search result and the initial query to generate a refined prompt, which is then being passed to Gemini for further processing.","metadata":{}},{"cell_type":"code","source":"def make_prompt(query, relevant_passage):\n    escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n    prompt = f\"\"\"\nYou are a financial risk analyst helping a non-technical audience understand potential risks faced by a company, based on excerpts from its official reports.\n\nRead the passage below and extract any **risks** that are either clearly mentioned or implied. These may include:\n- Financial risks (e.g., revenue decline, debt, liquidity)\n- Operational risks (e.g., supply chain issues, product delays)\n- Legal or regulatory risks\n- Competitive risks\n- Macroeconomic uncertainties (e.g., inflation, global demand)\n- Reputational risks\n\nSummarize these in **clear bullet points** or a short paragraph. Use plain English, and make it easy for someone without a finance background to understand. If no risk is found, say: *\"No significant risks mentioned in this section.\"*\n\nPASSAGE: {escaped}\n\nANSWER:\n\"\"\"\n    return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.933492Z","iopub.execute_input":"2025-04-21T06:31:58.933917Z","iopub.status.idle":"2025-04-21T06:31:58.940162Z","shell.execute_reply.started":"2025-04-21T06:31:58.933838Z","shell.execute_reply":"2025-04-21T06:31:58.938671Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"Gemeni function calling","metadata":{}},{"cell_type":"code","source":"def generate_content(request: str) -> str:\n  \"\"\"You are a financial expert skilled\"\"\"\n  # Set the temperature low to stabilise the output.\n  config = types.GenerateContentConfig(temperature=0.0)\n  response = client.models.generate_content(\n      model='gemini-2.0-flash',\n      config=config,\n      contents=[request],\n  )\n  \n  return response.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.941683Z","iopub.execute_input":"2025-04-21T06:31:58.942135Z","iopub.status.idle":"2025-04-21T06:31:58.948538Z","shell.execute_reply.started":"2025-04-21T06:31:58.942090Z","shell.execute_reply":"2025-04-21T06:31:58.947046Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"### Document Processing Function Invocation","metadata":{}},{"cell_type":"code","source":"pdf_path = '10Q_Q1_2025_as_filed.pdf'\nclean_text = raw_text_extraction(pdf_path)\nchunks = split_into_chunks(clean_text)\n\n    \n# Embed using your preferred GenAI method\nembedded_vectors = embed_chunks_with_genai(client, chunks)\n\n# Store in local DataFrame\ndf = build_embedding_dataframe(chunks, embedded_vectors)","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-21T06:31:58.949861Z","iopub.execute_input":"2025-04-21T06:31:58.950365Z","iopub.status.idle":"2025-04-21T06:32:09.842707Z","shell.execute_reply.started":"2025-04-21T06:31:58.950316Z","shell.execute_reply":"2025-04-21T06:32:09.841085Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"### Report Summary Extraction on Embedded Data","metadata":{}},{"cell_type":"code","source":"# Define your financial risk extraction query\nfinancial_risk_query =\"From the Apple 10-Q report for Q1 2025, extract all paragraphs or sections that discuss financial performance\"\n\"financial stability, cash flow, revenue, expenses, debt, or profitability. Also include any parts that mention\"\n\"risks â€” such as legal risks, regulatory risks, supply chain disruptions, competitive risks, macroeconomic uncertainties, or litigation.\"\n\n# Search for the most relevant document chunks\ntop_chunks = search_similar_chunks(financial_risk_query, df,client,1)\npassage=top_chunks.iloc[0] #Finding the best passage from the embedded chunk\npassage=passage['text']  #best passage text extraction\nprompt = make_prompt(financial_risk_query, passage)\nrisk_analysis_text = generate_content(prompt) #Prompt based on the embedded data\nMarkdown(risk_analysis_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:32:09.844163Z","iopub.execute_input":"2025-04-21T06:32:09.844568Z","iopub.status.idle":"2025-04-21T06:32:12.893679Z","shell.execute_reply.started":"2025-04-21T06:32:09.844535Z","shell.execute_reply":"2025-04-21T06:32:12.891546Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a breakdown of the potential risks identified in the provided text:\n\n*   **Macroeconomic Risks:** The report explicitly mentions that macroeconomic conditions, including inflation, interest rates, and currency fluctuations, could materially impact the company's results of operations and financial condition. This means that changes in the overall economy could negatively affect Apple's sales, profits, and financial stability.\n\n*   **Competitive Risks & Legal/Regulatory Risks:** The company is subject to antitrust investigations and litigation in various jurisdictions, including a lawsuit by the U.S. Department of Justice alleging monopolization. Unfavorable outcomes could lead to significant fines and changes in business practices, negatively impacting the company's financial performance and reputation. The company is also subject to Digital Markets Act investigations in the EU, which could result in fines and changes to business practices.\n\n*   **Legal/Regulatory Risks:** The company faces complex and changing laws and regulations worldwide, including those related to antitrust, privacy, data security, consumer protection, and environmental issues. Compliance with these laws is expensive, and violations could lead to liabilities, increased costs, and damage to the company's reputation.\n\n*   **Revenue Decline Risk (Greater China):** Sales in Greater China decreased due to lower iPhone sales, indicating a potential risk of declining revenue in this important market.\n\n*   **Currency Fluctuation Risk:** The company is exposed to foreign exchange rate risk, which can impact gross margins and the value of foreign currency-denominated assets and liabilities. While the company uses hedging strategies, there's no guarantee these will fully offset the impact of currency movements.\n\n*   **Gross Margin Volatility:** The report states that future gross margins can be impacted by a variety of factors and are expected to be subject to volatility and downward pressure. This suggests a risk of declining profitability on sales.\n\n*   **Customer Concentration Risk:** Two customers represent a significant portion of total trade receivables, indicating a risk if either of these customers were to experience financial difficulties or reduce their business with Apple. Similarly, two vendors represent a significant portion of total vendor non-trade receivables.\n\n*   **Product Introduction Risk:** The timing of new product introductions can impact net sales, and sales can be affected when consumers anticipate a product introduction. This suggests a risk of sales fluctuations based on product cycles.\n\n*   **Reliance on Licensing Arrangements:** The company earns revenue from licensing arrangements with Google and other companies, and changes to these arrangements due to government investigations and legal proceedings could materially adversely affect the company's ability to earn revenue.\n"},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"## Table Extraction\n\nText and tables are processed as distinct entities, where raw text is directly embedded, whereas tables are handled separately due to their structured format, requiring specialized processing to extract and utilize their contents effectively.\n","metadata":{}},{"cell_type":"code","source":"# Prompt template to extract structured table data\ndef build_prompt(page_number, page_text):\n    return (\n        f\"You are a financial data analyst expert at extracting structured data from SEC 10-Q filings.\\n\"\n        f\"This is page {page_number} of the Apple 10-Q report:\\n\\n\"\n        f\"{page_text}\\n\\n\"\n        \" Extract only **financial tables** in this page.\\n\\n\"\n        \" Important: Preserve the **hierarchy of rows** such as:\\n\"\n        \"- Main headers like 'ASSETS', 'LIABILITIES'\\n\"\n        \"- Subgroups like 'Current assets', 'Non-current assets'\\n\"\n        \"- Line items under each group (e.g., 'Cash and cash equivalents')\\n\\n\"\n        \" Return result as valid nested JSON using this format:\\n\"\n        \"{\\n\"\n        \"  \\\"page_number\\\": <int>,\\n\"\n        \"  \\\"tables\\\": [\\n\"\n        \"     {\\n\"\n        \"       \\\"table_number\\\": <int>,\\n\"\n        \"       \\\"title\\\": \\\"<table title>\\\",\\n\"\n        \"       \\\"data\\\": {\\n\"\n        \"         \\\"ASSETS\\\": {\\n\"\n        \"           \\\"Current assets\\\": {\\n\"\n        \"             \\\"Cash and cash equivalents\\\": [\\\"$30,299\\\", \\\"$29,943\\\"],\\n\"\n        \"             ...\\n\"\n        \"           },\\n\"\n        \"           \\\"Non-current assets\\\": { ... },\\n\"\n        \"           \\\"Total assets\\\": [\\\"$344,085\\\", \\\"$364,980\\\"]\\n\"\n        \"         }\\n\"\n        \"       }\\n\"\n        \"     }\\n\"\n        \"  ]\\n\"\n        \"}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:32:12.895658Z","iopub.execute_input":"2025-04-21T06:32:12.896538Z","iopub.status.idle":"2025-04-21T06:32:12.903581Z","shell.execute_reply.started":"2025-04-21T06:32:12.896481Z","shell.execute_reply":"2025-04-21T06:32:12.901931Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Extract tables from each page\nconfig = types.GenerateContentConfig(temperature=0.0)\n\ndef generate_table_json_from_page(prompt: str) -> dict:\n    try:\n        response = client.models.generate_content(\n            model='gemini-2.0-flash',\n            config=config,\n            contents=[prompt],\n        )\n        # Try to extract just the JSON from the text\n        import re, json\n        match = re.search(r\"\\{[\\s\\S]+\\}\", response.text)\n        if match:\n            return json.loads(match.group())\n    except Exception as e:\n        print(\"Error:\", e)\n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:32:12.904697Z","iopub.execute_input":"2025-04-21T06:32:12.905086Z","iopub.status.idle":"2025-04-21T06:32:12.912725Z","shell.execute_reply.started":"2025-04-21T06:32:12.905053Z","shell.execute_reply":"2025-04-21T06:32:12.911280Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"Processing each page to extract tables, and then converting the extracted data into JSON format to facilitate visualization and further analysis.","metadata":{}},{"cell_type":"code","source":"import pdfplumber\n\nall_pages_json = []\n#pdf_path = \"/kaggle/input/your-sec-pdf/apple_2025_10q.pdf\"\n\nwith pdfplumber.open(pdf_path) as pdf:\n    for i, page in enumerate(pdf.pages):\n        page_number = i + 1\n        page_text = page.extract_text()\n        \n        if not page_text or len(page_text.strip()) < 50:\n            continue  # Skip empty or too-short pages\n        \n        print(f\"Processing page {page_number}...\")\n\n        prompt = build_prompt(page_number, page_text)\n        page_result = generate_table_json_from_page(prompt)\n\n        if page_result:\n            all_pages_json.append(page_result)\n        else:\n            print(f\"Page {page_number} failed to extract - no table found.\")\n#print(all_pages_json)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:32:12.914388Z","iopub.execute_input":"2025-04-21T06:32:12.914817Z"}},"outputs":[{"name":"stdout","text":"Processing page 1...\nProcessing page 2...\nProcessing page 3...\nProcessing page 4...\nProcessing page 5...\nProcessing page 6...\nProcessing page 7...\nProcessing page 8...\nProcessing page 9...\nProcessing page 10...\nProcessing page 11...\nProcessing page 12...\nProcessing page 13...\nProcessing page 14...\nProcessing page 15...\nProcessing page 16...\nProcessing page 17...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### Metric Data Extraction\nThe FinancialAnalysisAgent utilizes also Gemini 2.0 as foundation generative model to extract \nstructure financial metrics from table-like content for visualization.\n\n          +---------------+\n          |  S0: Init     |\n          +---------------+\n                  |\n                  |  Initialize\n                  |  agent and receive\n                  |  query and content\n                  v\n          +---------------+\n          |  S3: Process  |\n          |  Request      |\n          +---------------+\n                  |\n                  |  Extract financial\n                  |  metrics from content\n                  v\n          +---------------+\n          |  S1: Extract  |\n          |  Metrics      |\n          +---------------+\n                  |\n                  |  Structure extracted\n                  |  data for visualization\n                  v\n          +---------------+\n          |  S2: Data     |\n          |  Structuring  |\n          +---------------+\n                  |\n                  |  Query matches a\n                  |  specific type\n                  v\n          +-------------------+\n          |  S4: Visualization|\n          +-------------------+\n                  |\n                  |  Visualization fails\n                  |  or data is empty\n                  v\n          +---------------+\n          |  S5: Error    |\n          |  Handling     |\n          +---------------+\n                  |\n                  |  Reset agent and\n                  |  restart process\n                  v\n          +---------------+\n          |  S0: Init     |\n          +---------------+\n","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport json\nimport re\nfrom typing import Dict, Any\n\n\nclass FinancialAnalysisAgent:\n    def __init__(self, api_key: str):\n        genai.configure(api_key=api_key)\n        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n\n    def extract_metrics(self, query: str, content: str) -> Dict:\n    # Use a chain-of-thought (step-by-step) structured prompt\n        prompt = f\"\"\"\n        You are a financial analysis assistant.\n\n        Your job is to extract **financial metric data** from the following content for **multiple time periods**, available in the content.\n\n        Step-by-step:\n        1. Read the user's query: \"{query}\"\n        2. Find the matching rows in the table-like content.\n        3. Extract values for **each year or quarter**, including all the available years.\n        4. Return a **valid JSON dictionary**, formatted like:\n        {{\n            \"Q1 2024\": {{\n                \"Product A\": 150,\n                \"Product B\": 200\n            }},\n            \"Q1 2023\": {{\n                \"Product A\": 140,\n                \"Product B\": 180\n            }}\n        }}\n\n        Rules:\n        - Include all the available years.\n        _ use '-' as time separator\n        - Do not include \"Total\", \"Percentage change\", or summary rows.\n        - Ensure all numbers are cleanly parsed.\n\n        Here is the table data:\n        {content}\n        \"\"\"\n        response = self.model.generate_content(prompt)\n        try:\n            match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n            return json.loads(match.group()) if match else {}\n        except Exception as e:\n            print(\" Error parsing model output to JSON:\", e)\n            return {}\n\n\n    def data_structuring(self, data: Dict):\n        if not data:\n            print(\"No revenue data found.\")\n            return None\n        try:\n            return data\n        except Exception as e:\n            print(\"Error:\", e)\n            return None\n\n    \n    def process_request(self, query: str, content: str):\n        metrics = self.extract_metrics(query, content)\n\n        if \"revenue by product\" in query.lower():\n            return self.data_structuring(metrics)\n        elif \"net income trend\" in query.lower():\n            return self.data_structuring(metrics)\n        elif \"cash flow\" in query.lower():\n            return self.data_structuring(metrics)\n        elif \"assets vs liabilities\" in query.lower():\n            return self.data_structuring(metrics)\n        elif \"revenue by geography\" in query.lower():\n            return self.data_structuring(metrics)\n        else:\n            print(\"No matching visualization found for the query.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Testing the Agent","metadata":{}},{"cell_type":"code","source":"# Run the agent\nfinacial_metric_agent = FinancialAnalysisAgent(api_key=GOOGLE_API_KEY)\n\n# Ask the agent to visualize revenue by product from Q1 2024\nquery = \"Revenue by product for Apple in 2024\"\nrevenue_by_product=finacial_metric_agent.process_request(query, content=all_pages_json)\nprint(revenue_by_product)\n\n#query = \"net income trend for Apple in Q1 2025\"\n#net_income_trend=agent.process_request(query, content=all_pages_json)\n#print(net_income_trend)\n\n#query = \"assets vs liabilities for Apple in Q1 2025\"\n#assets_vs_liabilities=agent.process_request(query, content=all_pages_json)\n#print(assets_vs_liabilities)\n\n#query = \"revenue by geography for Apple in 2024 and 2023\"\n#revenue_by_geography=agent.process_request(query, content=all_pages_json)\n#print(revenue_by_geography)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ploting Agent\n\nCalled **GenaiPlottingAgent** receives JSON data, generates plotting code using a Generative AI model, and executes it  to create the financial visualization of the data.\n\n                                  +------------------+\n                                  |  Initialization  |\n                                  +------------------+\n                                            |\n                                            |  Start\n                                            v\n                                  +------------------+\n                                  |  JSON Input      |\n                                  +------------------+\n                                            |\n                                            |  JSON received\n                                            v\n                                  +-------------------+\n                                  |  Prompt Creation  |\n                                  +-------------------+\n                                            |\n                                            |  Prompt generated\n                                            v\n                                  +-------------------+\n                                  |  Code Generation  |\n                                  +-------------------+\n                                            |\n                                            |  Code generated\n                                            v\n                                  +-------------------+\n                                  |  Code Execution   |\n                                  +-------------------+\n                                            |\n                                            |  Code executed\n                                            v\n                                  +-------------------+\n                                  |  Plot Display     |\n                                  +-------------------+\n","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nimport json\nfrom typing import Dict, Union, Any, Optional\nimport os\nimport matplotlib.pyplot as plt\nimport re\nimport ast\nimport warnings\n# Now your plotting code\nimport seaborn as sns\n\n# Suppress FutureWarnings globally (can be fine-tuned later)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nclass GenaiPlottingAgent:\n    \"\"\"\n    A plotting agent powered by Google's Generative AI (Gemini).\n    This agent takes JSON data as input and uses Gemini to generate\n    appropriate plotting code which is then executed.\n    \"\"\"\n   \n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"\n        Initialize the Genai Plotting Agent.\n       \n        Args:\n            api_key: Google API key for Gemini access (optional if set as env var)\n        \"\"\"\n        if api_key:\n            genai.configure(api_key=api_key)\n        else:\n            genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n\n        self.model = genai.GenerativeModel('gemini-2.0-flash')  # You can use 'gemini-pro' or 'gemini-1.5-pro'\n    def parse_json(self, json_input: Union[str, Dict]) -> Dict:\n        \"\"\"\n        Parse JSON input to ensure we have a dictionary.\n        \"\"\"\n        if isinstance(json_input, str):\n            return json.loads(json_input)\n        return json_input\n   \n    def generate_plot(self, json_data: Union[str, Dict]) -> None:\n        \"\"\"\n        Generate a plot based on provided JSON data.\n        \"\"\"\n        data = self.parse_json(json_data)\n        prompt = self._create_plotting_prompt(data)\n        config_with_code = types.GenerateContentConfig(\n            tools=[types.Tool(code_execution=types.ToolCodeExecution())],\n            temperature=0.0,\n        )\n    \n        self.config = config_with_code\n        response = self.model.generate_content(prompt)\n        code = self._extract_code_from_response(response)\n        \n        if code:\n            print(\"Executing generated plotting code...\")\n            try:\n                # Parse the code using ast\n                tree = ast.parse(code)\n                # Execute the code\n                exec(compile(tree, filename=\"<ast>\", mode=\"exec\"))\n            except Exception as e:\n                print(f\"Error executing generated code: {e}\")\n                #print(\"\\nGenerated code that caused the error:\")\n                #print(code)\n                self.generate_plot(json_data)\n        else:\n            print(\"No valid plotting code was generated.\")\n\n\n   \n    def _create_plotting_prompt(self, data: Dict) -> str:\n        \"\"\"\n        Create a prompt for Gemini to generate plotting code.\n        \"\"\"\n        # Automatically detect best plot type\n        analysis = self.analyze_data(data)\n        suggested_plot = analysis.get(\"plot_type\", \"line\")\n        data_str = json.dumps(data, indent=2)\n        prompt = f\"\"\"\n        You are a helpful Python plotting assistant. Generate **working, error-free** Python code to visualize the following JSON data using **matplotlib** and **seaborn**.\n        \n        ### INSTRUCTIONS:\n        - First, parse the JSON into a Python dictionary.\n        - considere plot type {suggested_plot}\n        - Assume the outer keys are **date strings** (e.g., 'December 30-2023'), and inner keys are **categories or regions with numeric values**.\n        - Convert the nested dictionary into a **pandas DataFrame** using `pd.DataFrame.from_dict(data, orient='index')` to simplify the transformation.\n        - Set the DataFrame index to the date values (as strings).\n        - Sort the index chronologically if needed for line plots.\n        - Plot each column (category) as a line using a loop with `plt.plot(...)`.\n        - Set appropriate axis labels, a title, and a legend.\n        - Use `plt.xticks(rotation=45)` to rotate date labels for readability.\n        - Use `plt.tight_layout()` to avoid layout overlap.\n        - Use `plt.savefig(data) with data variable name`\n        - Use `plt.show()` to display the plot.\n        - **Avoid putting labels inside the plotting loop**.\n        - Wrap the entire code in a single Python script block, inside triple backticks (```python).\n        - **Do not output any explanation**, only the code.\n        \n        ### JSON Data to visualize:\n        ```json\n        {data_str}\n            ```\n                \"\"\"\n        return prompt\n\n    def _extract_code_from_response(self, response) -> str:\n        \"\"\"\n        Extract Python code from the Gemini model response.\n       \n        Args:\n            response: Response from the Gemini model\n           \n        Returns:\n            Extracted Python code as string\n        \"\"\"\n        # Check if there's any code in the response\n        if hasattr(response, 'text'):\n            response_text = response.text\n        else:\n            # Handle different response structure\n            response_text = str(response)\n           \n        # Extract code between triple backticks\n        import re\n        code_blocks = re.findall(r'```python(.*?)```', response_text, re.DOTALL)\n       \n        if code_blocks:\n            return self._sanitize_code(code_blocks[0].strip())\n       \n        # If no code blocks with python tag, try without language specification\n        code_blocks = re.findall(r'```(.*?)```', response_text, re.DOTALL)\n        if code_blocks:\n            return self._sanitize_code(code_blocks[0].strip())\n       \n        # If still no code blocks, return the whole response\n        return self._sanitize_code(response_text.strip())\n\n    def _sanitize_code(self, code: str) -> str:\n        \"\"\"\n        Sanitize the generated code to ensure proper formatting.\n        \n        Args:\n            code: The generated code as a string.\n        \n        Returns:\n            Sanitized code as a string.\n        \"\"\"\n        import textwrap\n        return textwrap.dedent(code).strip()\n      \n    \n    def analyze_data(self, json_data: Union[str, Dict]) -> Dict:\n        \"\"\"\n        Use GenAI to analyze the structure of JSON data and select the best plot type.\n        \n        Args:\n            json_data: The JSON data to analyze\n        \n        Returns:\n            Dictionary with:\n                - plot_type: Best recommended plot type (string)\n                - reason: Explanation for the choice\n        \"\"\"\n        data = self.parse_json(json_data)\n        data_str = json.dumps(data, indent=2)\n    \n        prompt = f\"\"\"\n    Analyze the following JSON data and return a JSON object with the most appropriate plot type for visualization.\n    \n    ### Instructions:\n    - Return only a JSON object with the following keys:\n      - \"plot_type\": the single best matplotlib/seaborn chart type for this data (e.g., \"Time Series Plot\", \"line\", \"bar\",\"Area Chart\", \"Histogram\",\"heatmap\", \"scatter\", \"box\").\n      - \"reason\": a short explanation for choosing that plot type.\n    - Do not return multiple plot types.\n    - Do not include any explanation outside the JSON object.\n    \n    ### Data:\n    ```json\n    {data_str}\n        ```\n        \"\"\"\n        response = self.model.generate_content(prompt)\n        \n        try:\n            response_text = response.text if hasattr(response, 'text') else str(response)\n        \n            json_match = re.search(r'```json(.*?)```', response_text, re.DOTALL)\n            if json_match:\n                response_text = json_match.group(1).strip()\n        \n            response_text = response_text.replace(\"```\", \"\").strip()\n            return json.loads(response_text)\n        except Exception as e:\n            return {\n                \"plot_type\": \"line\",\n                \"reason\": \"Fallback: parsing error\",\n                \"error\": str(e),\n                \"raw_response\": response.text if hasattr(response, 'text') else str(response)\n            }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sample Test on Revenue by Product","metadata":{}},{"cell_type":"code","source":"plot_agent = GenaiPlottingAgent(api_key=GOOGLE_API_KEY)\nplot_agent.generate_plot(revenue_by_product)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Image plot Intepreter Agent\nCalled **ImageInterpreterAgent**, takes plot image, interprets it using a Generative AI model, and generates text based on the plot image and a given prompt.\n\n                                  +------------------+\n                                  |  Initialization  |\n                                  +------------------+\n                                            |\n                                            |  Model Loaded\n                                            v\n                                  +------------------+\n                                  |  Image Input     |\n                                  |  (image_path,    |\n                                  |   prompt)        |\n                                  +------------------+\n                                            |\n                                            |  Image Loaded\n                                            v\n                                  +------------------+\n                                  |  Interpret Image |\n                                  +------------------+\n                                            |\n                                            |  Text Generated\n                                            v\n                                  +-------------------+\n                                  |  Text Generation  |\n                                  +-------------------+\n                                            |\n                                            |  Text Returned\n                                            v\n                                  +--------------------+\n                                  |  Text Output       |\n                                  |  (interpreted text)|\n                                  +--------------------+\n","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom PIL import Image\nfrom io import BytesIO\n\n#use the modele availabe based on the region :\n#gemini-2.0-flash-exp-image-generation gemini-2.5-flash-preview-04-17  gemini-1.5-flash-8b gemini-2.0-flash\nclass ImageInterpreterAgent:\n    def __init__(self, model=\"gemini-2.0-flash-exp-image-generation\"):\n        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n        self.model = model\n\n    def interpret_image(self, image_path: str, prompt: str):\n        # Load the image\n        image = Image.open(image_path)\n        display(image)\n        # Prepare request\n        response = self.client.models.generate_content(\n            model=self.model,\n            contents=[prompt, image],\n            config=types.GenerateContentConfig(\n                response_modalities=['TEXT', 'IMAGE']\n            )\n        )\n\n        # Process and return text as we're only interested in text\n        answer=\"\"\n        for part in response.candidates[0].content.parts:\n            if part.text:\n                answer+= part.text + \"\\n\"\n        \n        return answer.strip()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Test","metadata":{}},{"cell_type":"code","source":"graphic_interpreter_agent = ImageInterpreterAgent()\nintepretation1=graphic_interpreter_agent.interpret_image('/kaggle/working/data.png', \"Explain shortly and summarize shortly lines max as a financial expert\")\nprint(intepretation1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Report Generation","metadata":{}},{"cell_type":"markdown","source":"Combine multiple sections with optional images, and then merges them into a single PDF file","metadata":{}},{"cell_type":"code","source":"!pip install markdown weasyprint PyPDF2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import markdown\nfrom weasyprint import HTML\nfrom PyPDF2 import PdfMerger\nfrom IPython.display import FileLink, display\nimport base64\nimport os\n\nclass MarkdownToPDFBuilder:\n    def __init__(self, output_pdf=\"combined_report.pdf\"):\n        self.section_pdfs = []\n        self.output_pdf = output_pdf\n\n    def add_section(self, title: str, text: str, image_path: str = None):\n        # Markdown to HTML\n        md_content = f\"# {title}\\n\\n{text}\"\n        html_content = markdown.markdown(md_content)\n\n        # Embed image if present\n        if image_path:\n            with open(image_path, \"rb\") as img_file:\n                img_data = base64.b64encode(img_file.read()).decode(\"utf-8\")\n                img_tag = f'<img src=\"data:image/png;base64,{img_data}\" style=\"max-width:50%; height:35%;\">'\n                html_content += f\"<br>{img_tag}\"\n\n        # Wrap in full HTML\n        full_html = f\"<html><body>{html_content}</body></html>\"\n\n        # Create individual PDF\n        temp_pdf = f\"temp_section_{len(self.section_pdfs) + 1}.pdf\"\n        HTML(string=full_html).write_pdf(temp_pdf)\n        self.section_pdfs.append(temp_pdf)\n\n        print(f\" Section added: {title}\")\n\n    def finalize(self):\n        # Merge all section PDFs\n        merger = PdfMerger()\n        for pdf in self.section_pdfs:\n            merger.append(pdf)\n        merger.write(self.output_pdf)\n        merger.close()\n    \n        abs_path = os.path.join(\"/kaggle/working/\", self.output_pdf)\n    \n        print(f\"\\n Final PDF saved to: {abs_path}\")\n        \n        # Show download link\n        #display(FileLink(abs_path, result_html_prefix=\"Click to download: \"))\n\n\n    def cleanup(self):\n        for f in self.section_pdfs:\n            try:\n                os.remove(f)\n                #print(f\"Deleted: {f}\")\n            except Exception as e:\n                print(f\" Could not delete {f}: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Main Execution\nGenerating a financial report, including risk analysis, revenue by product, net income trend, and assets vs liabilities all the plot possible by using various agents, financial metric, plot, and interpretation agents, to process and visualize the data continuously.","metadata":{}},{"cell_type":"code","source":"builder = MarkdownToPDFBuilder() #report builder\nbuilder.add_section(\"Risk Report\", risk_analysis_text)\ngraphic_prompt=\"\"\"You are a financial expert. Analyze, explain, and summarize the value changes shown in the plot. \nYour audience has no finance background,so keep your explanation clear and simple. \nFocus only on the key information and provide essential reasons behind the changes â€” not too detailed, \nbut enough to understand the important trends and what might be causing them.\"\"\"\n#FINANCIAL ANALYSYS AGENT instance\n#finacial_metric_agent used on the top\n\n#PLOTING AGENT instance\n#plot_agent = usend on the top\n\n#ITEPRETING AGENT instance\n#graphic_interpreter_agent used on the top\n\n# Processing revenue by product from Q1 2024\nquery = \"Revenue by product for Apple in 2024\"\nrevenue_by_product=finacial_metric_agent.process_request(query, content=all_pages_json)\nplot_agent.generate_plot(revenue_by_product)\nrevenue_by_product_intepretation=graphic_interpreter_agent.interpret_image('/kaggle/working/data.png',graphic_prompt)\nbuilder.add_section(\"Revenue Report\", revenue_by_product_intepretation, \"data.png\")\n\n# Processing revenue by product from Q1 2024\nquery = \"Net income trend for Apple in Q1 2025\"\nnet_income_trend=finacial_metric_agent.process_request(query, content=all_pages_json)\nplot_agent.generate_plot(net_income_trend)\nnet_income_trend_intepretation=graphic_interpreter_agent.interpret_image('/kaggle/working/data.png',graphic_prompt)\nbuilder.add_section(\"Net income Trend\", revenue_by_product_intepretation, \"data.png\")\n\n\nquery = \"Assets vs liabilities for Apple in Q1 2025\"\nassets_vs_liabilities=finacial_metric_agent.process_request(query, content=all_pages_json)\nplot_agent.generate_plot(assets_vs_liabilities)\nnet_income_trend_intepretation=graphic_interpreter_agent.interpret_image('/kaggle/working/data.png',graphic_prompt)\nbuilder.add_section(\"Assets vs liabilities\", net_income_trend_intepretation, \"data.png\")\n\n\nbuilder.finalize()\nbuilder.cleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## REFERENCES\n[Google AI](http://https://ai.google.dev/gemini-api/docs/models)\n\n**Finite State Machines in Hardware:** Theory and Design (with VHDL and SystemVerilog) by Volnei A. Pedroni.\n\n**Synthesis of Finite State Machines:** Logic Optimization by Tiziano Villa, Timothy Kam, Robert K. Brayton, and Alberto L. Sangiovanni-Vincentelli.\n\n**Digital Design and Computer Architecture by David Harris and Sarah Harris**.\n\n**Introduction to Automata Theory, Languages, and Computation** by John E. Hopcroft, Rajeev Motwani, and Jeffrey D. Ullman (covers FSM concepts extensively).\n\n**The Essentials of Risk Management** by Michel Crouhy, Dan Galai, and Robert Mark.\n\n**Financial Risk Management Fundamentals** by Jason Schenker.\n\n**Risk Management and Financial Institutions** by John C. Hull.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}